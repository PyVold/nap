# ============================================================================
# routes/ml_insights.py - ML Insights & Intelligence API
# ============================================================================

from fastapi import APIRouter, HTTPException, Depends, Query, Body
from sqlalchemy.orm import Session
from sqlalchemy import desc
from typing import Optional, List
from datetime import datetime, timedelta

from shared.database import get_db
from db_models import MLInsightDB, DeviceRiskScoreDB, MLModelMetadataDB
from services.ml_engine import ml_engine
from services.scheduler import analytics_scheduler

router = APIRouter(prefix="/ml", tags=["ML Insights"])


# ============================================================================
# ML Insights
# ============================================================================

@router.get("/insights")
async def get_insights(
    insight_type: Optional[str] = Query(None, description="Filter by type: trend, anomaly, prediction, recommendation"),
    category: Optional[str] = Query(None, description="Filter by category: compliance, health, security, risk"),
    include_dismissed: bool = Query(False, description="Include dismissed insights"),
    limit: int = Query(50, ge=1, le=200),
    db: Session = Depends(get_db)
):
    """
    Get ML-generated insights

    Returns actionable insights generated by the ML engine including:
    - Compliance trends and predictions
    - Anomaly alerts
    - Risk assessments
    - Recommendations
    """
    try:
        query = db.query(MLInsightDB)

        if insight_type:
            query = query.filter(MLInsightDB.insight_type == insight_type)
        if category:
            query = query.filter(MLInsightDB.category == category)
        if not include_dismissed:
            query = query.filter(MLInsightDB.dismissed == False)

        insights = query.order_by(desc(MLInsightDB.generated_at)).limit(limit).all()

        return [{
            "id": i.id,
            "type": i.insight_type,
            "category": i.category,
            "title": i.title,
            "description": i.description,
            "severity": i.severity.value if i.severity else None,
            "device_id": i.device_id,
            "metrics": i.related_metrics,
            "confidence": i.confidence_score,
            "is_actionable": i.is_actionable,
            "action_taken": i.action_taken,
            "dismissed": i.dismissed,
            "generated_at": i.generated_at.isoformat() if i.generated_at else None
        } for i in insights]

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch insights: {str(e)}")


@router.get("/insights/summary")
async def get_insights_summary(db: Session = Depends(get_db)):
    """
    Get summary of ML insights for dashboard display
    """
    try:
        # Get counts by type
        cutoff = datetime.utcnow() - timedelta(days=7)

        total = db.query(MLInsightDB).filter(
            MLInsightDB.generated_at >= cutoff,
            MLInsightDB.dismissed == False
        ).count()

        actionable = db.query(MLInsightDB).filter(
            MLInsightDB.generated_at >= cutoff,
            MLInsightDB.dismissed == False,
            MLInsightDB.is_actionable == True
        ).count()

        # Get by severity
        from models.enums import SeverityLevel
        critical = db.query(MLInsightDB).filter(
            MLInsightDB.generated_at >= cutoff,
            MLInsightDB.dismissed == False,
            MLInsightDB.severity == SeverityLevel.CRITICAL
        ).count()

        high = db.query(MLInsightDB).filter(
            MLInsightDB.generated_at >= cutoff,
            MLInsightDB.dismissed == False,
            MLInsightDB.severity == SeverityLevel.HIGH
        ).count()

        # Most recent insights
        recent = db.query(MLInsightDB).filter(
            MLInsightDB.dismissed == False
        ).order_by(desc(MLInsightDB.generated_at)).limit(5).all()

        return {
            "total_insights": total,
            "actionable_insights": actionable,
            "critical_count": critical,
            "high_count": high,
            "recent_insights": [{
                "id": i.id,
                "title": i.title,
                "type": i.insight_type,
                "severity": i.severity.value if i.severity else None,
                "generated_at": i.generated_at.isoformat() if i.generated_at else None
            } for i in recent]
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch insights summary: {str(e)}")


@router.post("/insights/{insight_id}/dismiss")
async def dismiss_insight(
    insight_id: int,
    dismissed_by: str = Body(..., embed=True),
    db: Session = Depends(get_db)
):
    """Dismiss an insight"""
    try:
        insight = db.query(MLInsightDB).filter(MLInsightDB.id == insight_id).first()

        if not insight:
            raise HTTPException(status_code=404, detail="Insight not found")

        insight.dismissed = True
        insight.dismissed_by = dismissed_by
        db.commit()

        return {"message": "Insight dismissed", "id": insight_id}

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to dismiss insight: {str(e)}")


@router.post("/insights/{insight_id}/action-taken")
async def mark_action_taken(
    insight_id: int,
    db: Session = Depends(get_db)
):
    """Mark an insight as having action taken"""
    try:
        insight = db.query(MLInsightDB).filter(MLInsightDB.id == insight_id).first()

        if not insight:
            raise HTTPException(status_code=404, detail="Insight not found")

        insight.action_taken = True
        db.commit()

        return {"message": "Action marked as taken", "id": insight_id}

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to mark action: {str(e)}")


# ============================================================================
# Risk Scores
# ============================================================================

@router.get("/risk-scores")
async def get_risk_scores(
    risk_level: Optional[str] = Query(None, description="Filter: low, medium, high, critical"),
    device_id: Optional[int] = None,
    limit: int = Query(100, ge=1, le=500),
    db: Session = Depends(get_db)
):
    """
    Get ML-calculated device risk scores

    Risk scores are calculated based on:
    - Compliance status
    - Health check results
    - Configuration drift
    - Audit freshness
    """
    try:
        query = db.query(DeviceRiskScoreDB)

        if risk_level:
            query = query.filter(DeviceRiskScoreDB.risk_level == risk_level)
        if device_id:
            query = query.filter(DeviceRiskScoreDB.device_id == device_id)

        # Get most recent score per device
        from sqlalchemy import func
        subquery = db.query(
            DeviceRiskScoreDB.device_id,
            func.max(DeviceRiskScoreDB.calculated_at).label('max_date')
        ).group_by(DeviceRiskScoreDB.device_id).subquery()

        query = query.join(
            subquery,
            (DeviceRiskScoreDB.device_id == subquery.c.device_id) &
            (DeviceRiskScoreDB.calculated_at == subquery.c.max_date)
        )

        scores = query.order_by(desc(DeviceRiskScoreDB.overall_risk_score)).limit(limit).all()

        return [{
            "id": s.id,
            "device_id": s.device_id,
            "overall_risk": round(s.overall_risk_score, 3),
            "risk_level": s.risk_level,
            "compliance_risk": round(s.compliance_risk, 3),
            "health_risk": round(s.health_risk, 3),
            "drift_risk": round(s.drift_risk, 3),
            "age_risk": round(s.age_risk, 3),
            "risk_factors": s.risk_factors or [],
            "recommendations": s.recommendations or [],
            "calculated_at": s.calculated_at.isoformat() if s.calculated_at else None
        } for s in scores]

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch risk scores: {str(e)}")


@router.get("/risk-scores/summary")
async def get_risk_summary(db: Session = Depends(get_db)):
    """Get summary of device risk distribution"""
    try:
        # Get latest scores
        from sqlalchemy import func
        subquery = db.query(
            DeviceRiskScoreDB.device_id,
            func.max(DeviceRiskScoreDB.calculated_at).label('max_date')
        ).group_by(DeviceRiskScoreDB.device_id).subquery()

        latest_scores = db.query(DeviceRiskScoreDB).join(
            subquery,
            (DeviceRiskScoreDB.device_id == subquery.c.device_id) &
            (DeviceRiskScoreDB.calculated_at == subquery.c.max_date)
        ).all()

        if not latest_scores:
            return {
                "total_devices": 0,
                "risk_distribution": {"low": 0, "medium": 0, "high": 0, "critical": 0},
                "average_risk": 0,
                "high_risk_devices": []
            }

        # Calculate distribution
        distribution = {"low": 0, "medium": 0, "high": 0, "critical": 0}
        for score in latest_scores:
            if score.risk_level in distribution:
                distribution[score.risk_level] += 1

        avg_risk = sum(s.overall_risk_score for s in latest_scores) / len(latest_scores)

        # Top high-risk devices
        high_risk = sorted(
            [s for s in latest_scores if s.risk_level in ['high', 'critical']],
            key=lambda x: x.overall_risk_score,
            reverse=True
        )[:5]

        return {
            "total_devices": len(latest_scores),
            "risk_distribution": distribution,
            "average_risk": round(avg_risk, 3),
            "high_risk_devices": [{
                "device_id": s.device_id,
                "risk_level": s.risk_level,
                "overall_risk": round(s.overall_risk_score, 3),
                "top_factor": s.risk_factors[0] if s.risk_factors else None
            } for s in high_risk]
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch risk summary: {str(e)}")


# ============================================================================
# Forecasting
# ============================================================================

@router.post("/forecast/generate")
async def generate_ml_forecast(
    device_id: Optional[int] = Body(None),
    days_ahead: int = Body(14, ge=1, le=90),
    db: Session = Depends(get_db)
):
    """
    Generate ML-powered compliance forecasts using Prophet/linear regression

    More sophisticated than basic forecasting, includes confidence intervals.
    """
    try:
        forecasts = ml_engine.forecast_compliance(db, device_id, days_ahead)

        if not forecasts:
            return {
                "message": "Insufficient historical data for ML forecasting (need 7+ data points)",
                "forecasts": []
            }

        return {
            "message": f"Generated {len(forecasts)} ML forecasts",
            "model": "Prophet" if len(forecasts) > 0 and 'lower_bound' in forecasts[0] else "Linear Regression",
            "forecasts": forecasts
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to generate forecast: {str(e)}")


# ============================================================================
# Anomaly Detection
# ============================================================================

@router.post("/anomalies/detect")
async def detect_ml_anomalies(
    device_id: Optional[int] = Body(None),
    sensitivity: float = Body(0.1, ge=0.01, le=0.5),
    db: Session = Depends(get_db)
):
    """
    Run ML anomaly detection using Isolation Forest algorithm

    Sensitivity controls contamination factor (0.01 = less sensitive, 0.5 = more sensitive)
    """
    try:
        anomalies = ml_engine.detect_anomalies(db, device_id, sensitivity)

        return {
            "message": f"Detected {len(anomalies)} anomalies",
            "algorithm": "Isolation Forest" if len(anomalies) > 0 else "Z-Score (fallback)",
            "anomalies": anomalies
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to detect anomalies: {str(e)}")


# ============================================================================
# Risk Scoring
# ============================================================================

@router.post("/risk-scores/calculate")
async def calculate_risk_scores(
    device_ids: Optional[List[int]] = Body(None, description="Device IDs to score (None = all)"),
    db: Session = Depends(get_db)
):
    """
    Trigger ML risk score calculation for devices

    Calculates weighted risk based on compliance, health, drift, and audit freshness.
    """
    try:
        # Trigger scheduler job
        result = await analytics_scheduler.run_job_now("risk_scoring")

        return {
            "message": "Risk scoring completed",
            "result": result
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to calculate risk scores: {str(e)}")


# ============================================================================
# Insight Generation
# ============================================================================

@router.post("/insights/generate")
async def generate_insights(db: Session = Depends(get_db)):
    """
    Trigger ML insight generation

    Analyzes trends, anomalies, and risks to generate actionable insights.
    """
    try:
        insights = ml_engine.generate_insights(db)

        return {
            "message": f"Generated {len(insights)} insights",
            "insights": insights
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to generate insights: {str(e)}")


# ============================================================================
# Scheduler Management
# ============================================================================

@router.get("/scheduler/status")
async def get_scheduler_status():
    """Get status of ML analytics scheduler and scheduled jobs"""
    try:
        status = analytics_scheduler.get_job_status()
        return status
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to get scheduler status: {str(e)}")


@router.post("/scheduler/run/{job_id}")
async def run_job_manually(job_id: str):
    """
    Manually trigger a scheduled ML job

    Available job IDs:
    - compliance_snapshot: Create compliance snapshot
    - ml_forecasting: Run ML forecasting
    - anomaly_detection: Run anomaly detection
    - risk_scoring: Calculate device risk scores
    - insight_generation: Generate ML insights
    """
    try:
        result = await analytics_scheduler.run_job_now(job_id)
        return result
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to run job: {str(e)}")


# ============================================================================
# Model Metadata
# ============================================================================

@router.get("/models")
async def get_model_metadata(
    model_name: Optional[str] = None,
    db: Session = Depends(get_db)
):
    """Get metadata about trained ML models"""
    try:
        query = db.query(MLModelMetadataDB)

        if model_name:
            query = query.filter(MLModelMetadataDB.model_name == model_name)

        models = query.order_by(desc(MLModelMetadataDB.trained_at)).limit(20).all()

        return [{
            "id": m.id,
            "model_name": m.model_name,
            "version": m.version,
            "trained_at": m.trained_at.isoformat() if m.trained_at else None,
            "training_samples": m.training_samples,
            "training_duration": m.training_duration_seconds,
            "accuracy": m.accuracy,
            "mae": m.mae,
            "mse": m.mse,
            "is_active": m.is_active
        } for m in models]

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch model metadata: {str(e)}")
